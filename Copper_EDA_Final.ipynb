{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavitharamanrk/CopperModel/blob/main/Copper_EDA_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Industrial Copper Modeling**"
      ],
      "metadata": {
        "id": "6GqPJvwNphhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Selling Price and Customer Status Prediction**"
      ],
      "metadata": {
        "id": "dIpbJXfP5AWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQApBVCpRsox"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import metrics\n",
        "import openpyxl\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading**"
      ],
      "metadata": {
        "id": "xVY1Wm21WPxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBaIXbUOR6B-"
      },
      "outputs": [],
      "source": [
        "# data load from excel file\n",
        "copper_original_ds=pd.read_excel(\"/content/Copper_Set.xlsx\" )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds=copper_original_ds.copy()"
      ],
      "metadata": {
        "id": "KEF9sGS0tUtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ile_gmx5Wn6Z"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Empty**"
      ],
      "metadata": {
        "id": "Cg6d4klsQdco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the column names\n",
        "copper_ds.columns"
      ],
      "metadata": {
        "id": "OnxnYvHV8mGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# column information\n",
        "copper_ds.info()"
      ],
      "metadata": {
        "id": "tTbEzl9r75xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# no of rows and columns\n",
        "copper_ds.shape"
      ],
      "metadata": {
        "id": "tQcwMH_yAoIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total no of null values in each column\n",
        "copper_ds.isna().sum()"
      ],
      "metadata": {
        "id": "KRLh7rXQ8Aet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_data = copper_ds.isnull().mean()\n",
        "pd.DataFrame({\n",
        "    \"column_name\": null_data.index,\n",
        "    \"Null values\":null_data.values\n",
        "}).sort_values(\"Null values\",ascending=False)"
      ],
      "metadata": {
        "id": "ogjX6Xu1P8EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# description of the column\n",
        "copper_ds.describe()"
      ],
      "metadata": {
        "id": "_4T2_sBqAMqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strip/replace**"
      ],
      "metadata": {
        "id": "v9efb_Z-G18Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlvqkK0sUkUZ"
      },
      "outputs": [],
      "source": [
        "# removing a string as quantity tons assuming as numerical\n",
        "copper_ds['quantity tons'].replace('e',np.nan, regex=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds['material_ref'] = copper_ds['material_ref'].astype(str).str.lstrip('0')"
      ],
      "metadata": {
        "id": "Af6jEAZBXQfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**imputation**"
      ],
      "metadata": {
        "id": "BSNIdpEa3MS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#numerical datatype using mean\n",
        "copper_ds['quantity tons'].fillna(copper_ds['quantity tons'].mean(), inplace=True)\n",
        "copper_ds['country'].fillna(copper_ds['country'].mean(), inplace=True)\n",
        "copper_ds['customer'].fillna(copper_ds['customer'].mean(), inplace=True)\n",
        "copper_ds['application'].fillna(copper_ds['application'].mean(), inplace=True)\n",
        "copper_ds['thickness'].fillna(copper_ds['thickness'].mean(), inplace=True)\n",
        "copper_ds['width'].fillna(copper_ds['width'].mean(), inplace=True)\n",
        "copper_ds['selling_price'].fillna(copper_ds['selling_price'].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "zUuaN-D5SLSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCW-e37JSNaR"
      },
      "outputs": [],
      "source": [
        "# Fill with mode\n",
        "copper_ds['status'].fillna(copper_ds['status'].mode().iloc[0], inplace=True)\n",
        "copper_ds['item_date'].fillna(copper_ds['item_date'].mode().iloc[0], inplace=True)\n",
        "copper_ds['delivery date'].fillna(copper_ds['delivery date'].mode().iloc[0], inplace=True)\n",
        "copper_ds['product_ref'].fillna(copper_ds['product_ref'].mode().iloc[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop null rows as 42% of the data is missing\n",
        "copper_ds['material_ref'].dropna(inplace=True)"
      ],
      "metadata": {
        "id": "cqotE_2XhnBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjmCMitLSNga"
      },
      "outputs": [],
      "source": [
        "# unique id col has 2 rows is null and its not create any impact on model so we can drop\n",
        "copper_ds.drop(\"id\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# other than won/lost rows has to delete - these records are in under progress\n",
        "condition = ~copper_ds['status'].isin(['Won', 'Lost'])\n",
        "copper_ds.drop(copper_ds[condition].index, inplace=True)"
      ],
      "metadata": {
        "id": "PIcjhtG-B2rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**duplication**"
      ],
      "metadata": {
        "id": "gm1SpSlgQvNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Duplicated datapoints: \",copper_ds.duplicated().sum())"
      ],
      "metadata": {
        "id": "72Gb4b02QyF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Number of \"0\" data availablity - sparcity**"
      ],
      "metadata": {
        "id": "tSiQOXonRB9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full row zero\n",
        "col_with_zero = []\n",
        "for i in copper_ds.columns:\n",
        "    perc_zero = (copper_ds[i]==0).mean()*100\n",
        "    col_with_zero.append((i,perc_zero))\n",
        "\n",
        "zero_percent = pd.DataFrame(col_with_zero,columns=['column_name','zero_percentage']).sort_values(\"zero_percentage\",ascending=False)\n",
        "zero_percent"
      ],
      "metadata": {
        "id": "z480DOd0OSUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o__4egpxpLN6"
      },
      "outputs": [],
      "source": [
        "# fill -ve values with mean\n",
        "mean_selling_price = copper_ds.loc[copper_ds['selling_price'] > 0, 'selling_price'].mean()\n",
        "copper_ds['selling_price'] = copper_ds['selling_price'].apply(lambda x: mean_selling_price if x <= 0 else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWfWzxj1qIAu"
      },
      "outputs": [],
      "source": [
        "# fill -ve values with mean\n",
        "mean_quantity_tons = copper_ds.loc[copper_ds['quantity tons'] > 0, 'quantity tons'].mean()\n",
        "copper_ds['quantity tons'] = copper_ds['quantity tons'].apply(lambda x: mean_quantity_tons if x <= 0 else x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Datatype Change**"
      ],
      "metadata": {
        "id": "amcMOnyCGpZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_dtPi7MSNXb"
      },
      "outputs": [],
      "source": [
        "copper_ds['quantity tons']=copper_ds['quantity tons'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds['delivery date']=copper_ds['delivery date'].astype(str)\n",
        "copper_ds['delivery_day']=copper_ds['delivery date'].str[6:8]\n",
        "copper_ds['delivery_month']=copper_ds['delivery date'].str[4:6]\n",
        "copper_ds['delivery_year']=copper_ds['delivery date'].str[:4]\n",
        "copper_ds['item_date']=copper_ds['item_date'].astype(str)\n",
        "copper_ds['item_day']=copper_ds['item_date'].str[6:8]\n",
        "copper_ds['item_month']=copper_ds['item_date'].str[4:6]\n",
        "copper_ds['item_year']=copper_ds['item_date'].str[:4]"
      ],
      "metadata": {
        "id": "WMfjiJejoBc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds['delivery_day']=copper_ds['delivery_day'].astype(int)\n",
        "copper_ds['delivery_month']=copper_ds['delivery_month'].astype(int)\n",
        "copper_ds['delivery_year']=copper_ds['delivery_year'].astype(int)\n",
        "copper_ds['item_day']=copper_ds['item_day'].astype(int)\n",
        "copper_ds['item_month']=copper_ds['item_month'].astype(int)\n",
        "copper_ds['item_year']=copper_ds['item_year'].astype(int)"
      ],
      "metadata": {
        "id": "ymY1o5TvoxKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds.drop('delivery date',axis=1,inplace=True)\n",
        "copper_ds.drop('item_date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "E0thKgogpiIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding**"
      ],
      "metadata": {
        "id": "BAf10OpSV-Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapping={'WI':'W','W':'W','S':'S','SLAWR':'S','IPL':'PL','PL':'PL','Others':'Others'}\n",
        "copper_ds['item type']=copper_ds['item type'].map(mapping)"
      ],
      "metadata": {
        "id": "tc_UWPyhHgN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status_mapping={'Won':1,\"Lost\":2}\n",
        "copper_ds['status']=copper_ds['status'].map(status_mapping)"
      ],
      "metadata": {
        "id": "eiZh3fAmsFi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_mapping={'W':1,'S':2,'PL':3,'Others':4}\n",
        "copper_ds['item type']=copper_ds['item type'].map(item_mapping)"
      ],
      "metadata": {
        "id": "d062EmRbsz2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "copper_ds['material_ref'] = le.fit_transform(copper_ds['material_ref'])"
      ],
      "metadata": {
        "id": "5PaJL3pbwOhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "538mibAFmQOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Statistical Analysis**"
      ],
      "metadata": {
        "id": "JyV_QGT2dgjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds.describe()"
      ],
      "metadata": {
        "id": "gWhaUkVVBzb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds.kurtosis()"
      ],
      "metadata": {
        "id": "5kuEVpuV9L6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds.skew()"
      ],
      "metadata": {
        "id": "yz7vmXO8-BGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds.boxplot(figsize=(20,8),rot=90,grid=True)"
      ],
      "metadata": {
        "id": "vpJZ0YrP_D-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_ds.hist(bins=50, figsize=(20,15))"
      ],
      "metadata": {
        "id": "V7Yx6R8Z_OHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(df, column):\n",
        "    sns.violinplot(data=df, x=column)\n",
        "    plt.title(f'Violin Plot for {column}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A5XHlhV3B3Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in copper_ds.columns:\n",
        "    plot(copper_ds, i)"
      ],
      "metadata": {
        "id": "kMVe76GTB9FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding Outliers"
      ],
      "metadata": {
        "id": "XG18QQ_DVv7Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1s79KRqlYeC"
      },
      "source": [
        "**IQR (Interquartile Range Method)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def out_iqr(df , column):\n",
        "    global lower,upper\n",
        "    q25, q75 = np.quantile(df[column], 0.25), np.quantile(df[column], 0.75)\n",
        "    # calculate the IQR\n",
        "    iqr = q75 - q25\n",
        "    cut_off = iqr * 1.5\n",
        "    lower, upper = q25 - cut_off, q75 + cut_off\n",
        "    df1 = df[df[column] > upper]\n",
        "    df2 = df[df[column] < lower]\n",
        "    return print(f'Total number of outliers in {column} :', df1.shape[0]+ df2.shape[0])"
      ],
      "metadata": {
        "id": "Qd6pkEenXYUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mvpkBHV2K2B"
      },
      "outputs": [],
      "source": [
        "iqr_ds=copper_ds.copy()\n",
        "for i in iqr_ds.columns:\n",
        "  out_iqr(iqr_ds,i)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "b7GnRQ7sEyNB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4ZZx2y6W8zt"
      },
      "source": [
        "# Log Transformation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the log transformation method to handle the skewness data\n",
        "copper_log_df = copper_ds.copy()\n",
        "copper_log_df['quantity tons_log'] = np.log(copper_log_df['quantity tons'])\n",
        "copper_log_df['thickness_log'] = np.log(copper_log_df['thickness'])\n",
        "copper_log_df['width_log'] = np.log(copper_log_df['width'])\n",
        "copper_log_df['selling_price_log'] = np.log(copper_log_df['selling_price'])\n",
        "copper_log_df"
      ],
      "metadata": {
        "id": "6lv4VdmyEmQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill -ve values with mean\n",
        "mean_selling_price_log = copper_log_df.loc[copper_log_df['selling_price_log'] > 0, 'selling_price_log'].mean()\n",
        "copper_log_df['selling_price_log'] = copper_log_df['selling_price_log'].apply(lambda x: mean_selling_price_log if x <= 0 else x)\n",
        "mean_quantity_tons_log = copper_log_df.loc[copper_log_df['quantity tons_log'] > 0, 'quantity tons_log'].mean()\n",
        "copper_log_df['quantity tons_log'] = copper_log_df['quantity tons_log'].apply(lambda x: mean_quantity_tons_log if x <= 0 else x)\n",
        "mean_thickness_log = copper_log_df.loc[copper_log_df['thickness_log'] > 0, 'thickness_log'].mean()\n",
        "copper_log_df['thickness_log'] = copper_log_df['thickness_log'].apply(lambda x: mean_thickness_log if x <= 0 else x)"
      ],
      "metadata": {
        "id": "b5sTy6FkWBiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_log_df.drop(['quantity tons','thickness','width','selling_price'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "sDkSHxozFF7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copper_log_df.hist(bins=50, figsize=(20,15))"
      ],
      "metadata": {
        "id": "JSj7K_23Jd1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Selection**"
      ],
      "metadata": {
        "id": "l58d7ljX2r9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation Analysis**"
      ],
      "metadata": {
        "id": "bLBLDLsIEKKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_data=copper_ds.corr()\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.heatmap(corr_data,annot=True,cmap=\"coolwarm\",fmt=\".2f\")"
      ],
      "metadata": {
        "id": "yuxRApPMX5N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA1nScSxCw6p"
      },
      "source": [
        "# Selling Price Prediction - Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oirBSj-HDQM9"
      },
      "outputs": [],
      "source": [
        "regrsn_df=copper_log_df.copy()\n",
        "regrsn_df.drop(['customer','item type','country','status','application','product_ref','material_ref','delivery_day','delivery_month','delivery_year','item_day','item_month','item_year'],axis=1, inplace=True)\n",
        "regrsn_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DidokQUjDElg"
      },
      "outputs": [],
      "source": [
        "y= regrsn_df['selling_price_log']\n",
        "x = regrsn_df.drop('selling_price_log', axis =1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model selection"
      ],
      "metadata": {
        "id": "oIgrvG4LqXLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLpLLHMMwoF1"
      },
      "outputs": [],
      "source": [
        "# check any null values in data\n",
        "regrsn_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_eiPwz4C5Bt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=40)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T42E1YJq0u14"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rfr = RandomForestRegressor().fit(x_train, y_train)\n",
        "y_pred= model_rfr.predict(x_test)\n",
        "print('MAE:',metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_test, y_pred))\n",
        "print('R2:',metrics.r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEpB_blx0vFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "model_abr = AdaBoostRegressor().fit(x_train, y_train)\n",
        "y_pred=model_abr.predict(x_test)\n",
        "print('MAE:',metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_test, y_pred))\n",
        "print('R2:',metrics.r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHNXBSvrMdPm"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model_gbr = GradientBoostingRegressor(max_depth=40).fit(x_train, y_train)\n",
        "y_pred=model_gbr.predict(x_test)\n",
        "print('MAE:',metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_test, y_pred))\n",
        "print('R2:',metrics.r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "test_data=np.array([[3.99,0.69,7.31]])\n",
        "y_pred=model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "xgRAjYZBLE0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "test_data=np.array([[3.99,0.69,7.31]])\n",
        "y_pred=model_abr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "oNwrxQfZMCw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "test_data=np.array([[3.99,0.69,7.31]])\n",
        "y_pred=model_gbr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "x9UY5mYOMEBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regrsn_df.head(2)"
      ],
      "metadata": {
        "id": "IXqbhjhIvmjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmWihBCZPx0X"
      },
      "outputs": [],
      "source": [
        "with open('/content/regression_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_abr, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoMl8LfZP_32"
      },
      "outputs": [],
      "source": [
        "# load the pickle model to predict selling price\n",
        "\n",
        "with open('/content/regression_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aku1WkCR0w2L"
      },
      "source": [
        "# Status Prediction - Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTOq5yYb0wKz"
      },
      "outputs": [],
      "source": [
        "df_clssfctn=copper_log_df[['quantity tons_log','country','item type','application','thickness_log','width_log','product_ref','selling_price_log','status']].copy()\n",
        "df_clssfctn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVLZPiCnT2SG"
      },
      "outputs": [],
      "source": [
        "# assign target and features\n",
        "y= df_clssfctn['status']\n",
        "x = df_clssfctn.drop('status', axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg2blis7iXs5"
      },
      "outputs": [],
      "source": [
        "df_clssfctn.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlhPl_kVWVJG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=32)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGGACHA7rSEY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFwWGgJTWVYY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YisOY89XWVlv"
      },
      "outputs": [],
      "source": [
        "# General for checking different models\n",
        "def classification_model_selection(ModelName, x_train, y_train, x_test, y_test,test_data):\n",
        "  model = ModelName().fit(x_train, y_train)\n",
        "  y_pred=model.predict(x_test)\n",
        "  accuracy=accuracy_score(y_test, y_pred)\n",
        "  mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "  aberr=metrics.mean_absolute_error(y_test, y_pred)\n",
        "  y_pred=model.predict(test_data)\n",
        "  res=\"Accuracy: \" + str(accuracy) + \" MSE: \" + str(mse) + \" MAE: \" + str(aberr) + \"   \" +str(y_pred[0])\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clssfctn"
      ],
      "metadata": {
        "id": "ckWKNexeM5BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifFgHWjDoHle"
      },
      "outputs": [],
      "source": [
        "# Checking for different models\n",
        "test_data=np.array([[6.9,25,1,41,1.1,7.12,164141591,6.40]])\n",
        "print(classification_model_selection(RandomForestClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(AdaBoostClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(GradientBoostingClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(ExtraTreesClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(DecisionTreeClassifier, x_train, y_train, x_test, y_test,test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u47zdBb3hZX"
      },
      "outputs": [],
      "source": [
        "  # This method is used to predict the status based on its processing time and accuracy\n",
        "  model = RandomForestClassifier().fit(x_train, y_train)\n",
        "  y_pred=model.predict(x_test)\n",
        "  test_data=np.array([[6.9,25,1,41,1.1,7.12,164141591,6.40]])\n",
        "  y_pred=model.predict(test_data)\n",
        "  y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV2oIl29WWFI"
      },
      "outputs": [],
      "source": [
        "# write pickle for classification\n",
        "with open('/content/classification_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyx1DW6LWWJ5"
      },
      "outputs": [],
      "source": [
        "# load the pickle model to predict status\n",
        "with open('/content/classification_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQwI0cfVYNQ_"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(np.array([[6.9,25,1,41,1.1,7.12,164141591,6.40]]))\n",
        "y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcyNEKhaWWdu"
      },
      "outputs": [],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFaW88e3MbIb"
      },
      "outputs": [],
      "source": [
        "# Streamlit file for deployment\n",
        "%%writefile app.py\n",
        "import numpy as np\n",
        "import pickle\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "#streamlit  page setting\n",
        "icon = Image.open(\"ml.jpg\")\n",
        "st.set_page_config(page_title= \"Copper EDA - Kavitha\",\n",
        "                page_icon= icon,\n",
        "                layout= \"wide\",\n",
        "                initial_sidebar_state= \"expanded\",\n",
        "                )\n",
        "\n",
        "st.subheader(\":blue[Industrial Copper Modeling]\")\n",
        "tab1,tab2,tab3=st.tabs([\":blue[Selling Price Prediction]\",\":blue[Status Prediction]\",\":blue[About]\"])\n",
        "\n",
        "with tab1:\n",
        "  col1,col2,col3=st.columns(3)\n",
        "  with col1:\n",
        "    txt_width=st.number_input(\"Enter the width\")\n",
        "    #res=checkempty(txt_width,\"width\")\n",
        "  with col2:\n",
        "    txt_quantity_tons=st.number_input(\"Enter the quantity in tons\")\n",
        "  with col3:\n",
        "    txt_thickness=st.number_input(\"Enter the thickness\")\n",
        "  if st.button(\"Predict Selling Price\", key=\"predict\"):\n",
        "      # load the regression pickle model\n",
        "      with open('/content/regression_model.pkl', 'rb') as f:\n",
        "          model = pickle.load(f)\n",
        "\n",
        "      # make array for all user input values in required order for model prediction\n",
        "      user_data = np.array([[txt_width,\n",
        "                          np.log(float(txt_quantity_tons)),\n",
        "                          np.log(float(txt_thickness))]])\n",
        "\n",
        "      # model predict the selling price based on user input\n",
        "      y_pred = model.predict(user_data)\n",
        "\n",
        "      # inverse transformation for log transformation data\n",
        "      selling_price = np.exp(y_pred[0])\n",
        "\n",
        "      # round the value with 2 decimal point\n",
        "      selling_price = round(selling_price, 2)\n",
        "      st.write(\"Predicted Selling Price: \", selling_price)\n",
        "\n",
        "with tab2:\n",
        "  col4,col5,col6=st.columns(3)\n",
        "  with col4:\n",
        "    txt_quantity_tons=st.number_input(\"Enter the quantity tons\")\n",
        "    txt_country=st.number_input(\"Enter country\")\n",
        "    txt_item_type=st.number_input(\"Enter item type\")\n",
        "  with col5:\n",
        "    txt_application=st.number_input(\"Enter application\")\n",
        "    txt_thickness=st.number_input(\"Enter thickness\")\n",
        "    txt_width=st.number_input(\"Enter width\")\n",
        "  with col6:\n",
        "    txt_product_ref=st.number_input(\"Enter product ref\")\n",
        "    txt_selling_price=st.number_input(\"Enter selling price\")\n",
        "\n",
        "  if st.button(\"Predict Status\", key=\"Predict Status\"):\n",
        "      # load the classification pickle model\n",
        "      with open('/content/classification_model.pkl', 'rb') as f:\n",
        "          model = pickle.load(f)\n",
        "\n",
        "      user_data = np.array([[txt_quantity_tons, txt_country, txt_item_type, txt_application,\n",
        "                            txt_thickness, txt_width, txt_product_ref, txt_selling_price]])\n",
        "\n",
        "      # model predict status based on user input\n",
        "      y_pred = model.predict(user_data)\n",
        "\n",
        "      status = y_pred[0]\n",
        "      if status==0:\n",
        "        st.success(\"Status: Lost - Failure\")\n",
        "      elif status==1:\n",
        "        st.success(\"Won - Success\")\n",
        "with tab3:\n",
        "    st.caption(\":blue[Overview:]\")\n",
        "    st.caption(\":blue[Original Copper dataset has null and zero values]\")\n",
        "    st.caption(\":blue[Data Cleaning has done for the all the null values and negative values]\")\n",
        "    st.caption(\":blue[log transformation is applied for selling price prediction]\")\n",
        "    st.caption(\":blue[3 features(quantity tons, width and thickness) has been taken for selling price prediction]\")\n",
        "    st.caption(\":blue[Won and lost status has been taken for prediction other status data has been removed]\")\n",
        "    st.caption(\":blue[all features has been taken for status prediction except item date and delivery date]\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "av1y_yIPd9Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "1yIFLxYGeBhy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3uOxA6F1Zb324OIznuw2g",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}