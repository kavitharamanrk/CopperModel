{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cdejUPeRoC2"
      },
      "outputs": [],
      "source": [
        "pip install dataprep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UQApBVCpRsox"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from dataprep.eda import create_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DBaIXbUOR6B-"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel(\"/content/Copper_Set.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ile_gmx5Wn6Z"
      },
      "source": [
        "# Finding Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX6CBts02a3t"
      },
      "outputs": [],
      "source": [
        "create_report(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf5hcRwCSNEM"
      },
      "outputs": [],
      "source": [
        "# verify the number of unique values in each col\n",
        "for i in list(df.columns):\n",
        "  print(f\"{i}:{df[i].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWWMtyE7SNMX"
      },
      "outputs": [],
      "source": [
        "# check any null values in data\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v23XgdOrSNH1"
      },
      "outputs": [],
      "source": [
        "# verify datatypes of all column\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbvJDcbrWz0e"
      },
      "source": [
        "# Pre processing / Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9wg7SJsSNOk"
      },
      "outputs": [],
      "source": [
        "# ‘Material_ref’ which starts with ‘00000’ value which should be converted into null\n",
        "df['material_ref'] = df['material_ref'].apply(lambda x: np.nan if str(x).startswith('00000') else x)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HlvqkK0sUkUZ"
      },
      "outputs": [],
      "source": [
        "# removing a string as quantity tons assuming as numerical\n",
        "df['quantity tons'].replace('e',np.nan, regex=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l_dtPi7MSNXb"
      },
      "outputs": [],
      "source": [
        "df['quantity tons']=df['quantity tons'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "e9CAcRD2SNUc"
      },
      "outputs": [],
      "source": [
        "#numerical datatype using median\n",
        "df['quantity tons'].fillna(df['quantity tons'].median(), inplace=True)\n",
        "df['customer'].fillna(df['customer'].median(), inplace=True)\n",
        "df['application'].fillna(df['application'].median(), inplace=True)\n",
        "df['thickness'].fillna(df['thickness'].median(), inplace=True)\n",
        "df['width'].fillna(df['width'].median(), inplace=True)\n",
        "df['selling_price'].fillna(df['selling_price'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LCW-e37JSNaR"
      },
      "outputs": [],
      "source": [
        "# Fill with mode\n",
        "df['country'].fillna(df['country'].mode().iloc[0], inplace=True)\n",
        "df['status'].fillna(df['status'].mode().iloc[0], inplace=True)\n",
        "df['item_date'].fillna(df['item_date'].mode().iloc[0], inplace=True)\n",
        "df['delivery date'].fillna(df['delivery date'].mode().iloc[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "o__4egpxpLN6"
      },
      "outputs": [],
      "source": [
        "# fill -ve values with mean\n",
        "mean_selling_price = df.loc[df['selling_price'] > 0, 'selling_price'].mean()\n",
        "df['selling_price'] = df['selling_price'].apply(lambda x: mean_selling_price if x <= 0 else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxMw1HDvqH-A"
      },
      "outputs": [],
      "source": [
        "# checking is -ve values in quantity tons\n",
        "df.loc[df['quantity tons'] <=0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rWfWzxj1qIAu"
      },
      "outputs": [],
      "source": [
        "# fill -ve values with mean\n",
        "mean_quantity_tons = df.loc[df['quantity tons'] > 0, 'quantity tons'].mean()\n",
        "df['quantity tons'] = df['quantity tons'].apply(lambda x: mean_quantity_tons if x <= 0 else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ka55sAmSNdN"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VjmCMitLSNga"
      },
      "outputs": [],
      "source": [
        "# more than 50% null values in material_ref\n",
        "df.drop(\"material_ref\", axis=1, inplace=True)\n",
        "# 2 rows is null in id column and its not create any impact on model so we can drop\n",
        "df.drop(\"id\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZdG_fXmWX5N",
        "outputId": "e899541c-15bc-4e1f-ea45-a4bc9244e705"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['W', 'WI', 'S', 'Others', 'PL', 'IPL', 'SLAWR'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df['item type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-xxgr0Bmf5aT"
      },
      "outputs": [],
      "source": [
        "# categorical data changed into numerical\n",
        "df['item type'] = df['item type'].map({'W':0, 'WI':1, 'S':2, 'PL':3, 'IPL':4,\n",
        "                                 'SLAWR':5, 'Others':6})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fClfVUk3p0ED"
      },
      "source": [
        "# Box, Distribution, Violin plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fxgK5mxWYdA"
      },
      "outputs": [],
      "source": [
        "# box plot, hist plot and violin plot\n",
        "def plot(df, column):\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    sns.boxplot(data=df, x=column)\n",
        "    plt.title(f'Box Plot for {column}')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    sns.histplot(data=df, x=column, kde=True, bins=50)\n",
        "    plt.title(f'Distribution Plot for {column}')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    sns.violinplot(data=df, x=column)\n",
        "    plt.title(f'Violin Plot for {column}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6PRFVEdWnHZ"
      },
      "outputs": [],
      "source": [
        "# These 4 columns taken for prediction.\n",
        "\n",
        "for i in ['quantity tons', 'thickness', 'width', 'selling_price']:\n",
        "    plot(df, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4ZZx2y6W8zt"
      },
      "source": [
        "# Log Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hrCBcndWYgq"
      },
      "outputs": [],
      "source": [
        "# using the log transformation method to handle the skewness data\n",
        "df_log = df.copy()\n",
        "df_log['quantity tons_log'] = np.log(df_log['quantity tons'])\n",
        "df_log['thickness_log'] = np.log(df_log['thickness'])\n",
        "df_log['selling_price_log'] = np.log(df_log['selling_price'])\n",
        "df_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwTn5VKVWYjw"
      },
      "outputs": [],
      "source": [
        "df_log.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXOMLOvFWYnB"
      },
      "outputs": [],
      "source": [
        "# after log transformation the data are normally distributed and reduced the skewness. [hist plot and violin plot]\n",
        "for i in ['quantity tons_log', 'thickness_log', 'width', 'selling_price_log']:\n",
        "    plot(df_log, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY2sitCgr_MV"
      },
      "outputs": [],
      "source": [
        "# checking any -ve values in log transformed data\n",
        "df_log[df_log['selling_price_log']<=0]\n",
        "df_log[df_log['quantity tons_log']<0]\n",
        "df_log[df_log['thickness_log']<0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WRK6dKrFguxZ"
      },
      "outputs": [],
      "source": [
        "# fill -ve values with mean\n",
        "mean_selling_price_log = df_log.loc[df_log['selling_price_log'] > 0, 'selling_price_log'].mean()\n",
        "df_log['selling_price_log'] = df_log['selling_price_log'].apply(lambda x: mean_selling_price_log if x <= 0 else x)\n",
        "mean_quantity_tons_log = df_log.loc[df_log['quantity tons_log'] > 0, 'quantity tons_log'].mean()\n",
        "df_log['quantity tons_log'] = df_log['quantity tons_log'].apply(lambda x: mean_quantity_tons_log if x <= 0 else x)\n",
        "mean_thickness_log = df_log.loc[df_log['thickness_log'] > 0, 'thickness_log'].mean()\n",
        "df_log['thickness_log'] = df_log['thickness_log'].apply(lambda x: mean_thickness_log if x <= 0 else x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1s79KRqlYeC"
      },
      "source": [
        "# IQR Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNFzGUyn5xgI"
      },
      "outputs": [],
      "source": [
        "df_iqr = df_log.copy()\n",
        "df_iqr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObjYHu_9WYrB"
      },
      "outputs": [],
      "source": [
        "# Using IQR and clip() methods to handle the outliers and add a new column of dataframe\n",
        "\n",
        "def outlier(df, column):\n",
        "    iqr = df[column].quantile(0.75) - df[column].quantile(0.25)\n",
        "    upper_threshold = df[column].quantile(0.75) + (1.5*iqr)\n",
        "    lower_threshold = df[column].quantile(0.25) - (1.5*iqr)\n",
        "    df[column] = df[column].clip(lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mvpkBHV2K2B"
      },
      "outputs": [],
      "source": [
        "outlier(df_iqr, 'quantity tons_log')\n",
        "outlier(df_iqr, 'thickness_log')\n",
        "outlier(df_iqr, 'selling_price_log')\n",
        "outlier(df_iqr, 'width')\n",
        "df_iqr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2KXMFF46EQz"
      },
      "outputs": [],
      "source": [
        "df_iqr.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajk6RKFxu4L4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# transform the outliers to within range using IQR and clip() methods - box plot\n",
        "\n",
        "for i in ['quantity tons_log', 'thickness_log', 'width', 'selling_price_log']:\n",
        "    plot(df_iqr, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqv2hgtFu5Ui"
      },
      "outputs": [],
      "source": [
        "# after add the new column of 'quantity tons_log', 'thickness_log', 'selling_price_log', drop the existing columns\n",
        "df_iqr.drop(columns=['quantity tons', 'thickness', 'selling_price'], inplace=True)\n",
        "df_iqr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piTKOqRsu5bP"
      },
      "outputs": [],
      "source": [
        "# Need to verify any columns are highly correlated using Heatmap. If any columns correalaion value >= 0.7 (absolute value), drop the columns.\n",
        "\n",
        "col = ['quantity tons_log','customer','country','status','application','width','product_ref','thickness_log','selling_price_log']\n",
        "df_heatmap = df_iqr[col].corr()\n",
        "sns.heatmap(df_heatmap, annot=True, linewidths=0.5, fmt='.2f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZE19Hkpu5fY"
      },
      "outputs": [],
      "source": [
        "# The highest value is (0.4 or -0.42) only, So there is no columns are highly correlated and no need to drop any columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA1nScSxCw6p"
      },
      "source": [
        "# Selling Price Prediction - Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oirBSj-HDQM9"
      },
      "outputs": [],
      "source": [
        "df_regrsn=df_iqr.copy()\n",
        "df_regrsn.drop(['item_date','customer','country','status','item type','application','product_ref','delivery date'],axis=1, inplace=True)\n",
        "df_regrsn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFP6MXcnpNWS"
      },
      "outputs": [],
      "source": [
        "create_report(df_regrsn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DidokQUjDElg"
      },
      "outputs": [],
      "source": [
        "y= df_regrsn['selling_price_log']\n",
        "x = df_regrsn.drop('selling_price_log', axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLpLLHMMwoF1"
      },
      "outputs": [],
      "source": [
        "# check any null values in data\n",
        "df_regrsn.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_eiPwz4C5Bt",
        "outputId": "8d728cd4-5d9f-4e1f-e017-e99ca75683a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((145338, 3), (36335, 3), (145338,), (36335,))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MaLohG8b0uPU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T42E1YJq0u14"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rfr = RandomForestRegressor(max_depth=40).fit(x_train, y_train)\n",
        "y_pred= model_rfr.predict(x_test)\n",
        "print(metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(metrics.mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErYd6zHAJUdu"
      },
      "outputs": [],
      "source": [
        "df_regrsn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEpB_blx0vFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "model_abr = AdaBoostRegressor().fit(x_train, y_train)\n",
        "y_pred=model_abr.predict(x_test)\n",
        "print(metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(metrics.mean_squared_error(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHNXBSvrMdPm"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model_gbr = GradientBoostingRegressor(max_depth=40).fit(x_train, y_train)\n",
        "y_pred=model_gbr.predict(x_test)\n",
        "print(metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(metrics.mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17F3A02HNE-6"
      },
      "outputs": [],
      "source": [
        "# Sample data\n",
        "test_data=np.array([[1220,4.6296,1.1006]])\n",
        "y_pred_gbr=model_gbr.predict(test_data)\n",
        "\n",
        "y_pred_gbr[0]  , np.exp(y_pred_gbr[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSfdIAFIJOSR"
      },
      "outputs": [],
      "source": [
        "# Sample data\n",
        "test_data=np.array([[1220,4.6296,1.1006]])\n",
        "y_pred_abr=model_abr.predict(test_data)\n",
        "y_pred_rfr=model_rfr.predict(test_data)\n",
        "y_pred_abr[0]  , y_pred_rfr[0] , np.exp(y_pred_abr[0]),np.exp(y_pred_rfr[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "FmWihBCZPx0X"
      },
      "outputs": [],
      "source": [
        "with open('/content/regression_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_gbr, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QoMl8LfZP_32"
      },
      "outputs": [],
      "source": [
        "# load the pickle model to predict selling price\n",
        "\n",
        "with open('/content/regression_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFJ0X9AwXxug"
      },
      "outputs": [],
      "source": [
        "# Sample test data 2\n",
        "y_pred = model.predict(np.array([[1240,6.0080,1.1006]]))\n",
        "np.exp(y_pred[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aku1WkCR0w2L"
      },
      "source": [
        "# Status Prediction - Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kTOq5yYb0wKz"
      },
      "outputs": [],
      "source": [
        "# Filter Won and Lost data for status prediction instead deleting rows\n",
        "df_clssfctn=df.query('status==\"Won\" or status==\"Lost\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clssfctn.drop(['item_date','customer','delivery date'],axis=1, inplace=True)\n",
        "df_clssfctn"
      ],
      "metadata": {
        "id": "XtvdrhkU-wQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsglJN4Ra96V",
        "outputId": "cfe1e0cc-3f4a-41d7-d948-d995e80b9da8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Won', 'Lost'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "df_clssfctn['status'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSH8IYkv83C-"
      },
      "outputs": [],
      "source": [
        "df_clssfctn['status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak8EgIdqa7P3"
      },
      "outputs": [],
      "source": [
        "df_clssfctn['status'] = OrdinalEncoder().fit_transform(df_clssfctn[['status']])\n",
        "df_clssfctn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu8nWeOoT2GP"
      },
      "outputs": [],
      "source": [
        "create_report(df_clssfctn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eVLZPiCnT2SG"
      },
      "outputs": [],
      "source": [
        "# assign target and features\n",
        "y= df_clssfctn['status']\n",
        "x = df_clssfctn.drop('status', axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg2blis7iXs5"
      },
      "outputs": [],
      "source": [
        "df_clssfctn.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlhPl_kVWVJG",
        "outputId": "6e837592-e2a3-43e9-aecc-686bd7e2ec1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120360, 8), (30090, 8), (120360,), (30090,))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=32)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "wGGACHA7rSEY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tFwWGgJTWVYY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YisOY89XWVlv"
      },
      "outputs": [],
      "source": [
        "# General for checking different models\n",
        "def classification_model_selection(ModelName, x_train, y_train, x_test, y_test,test_data):\n",
        "  model = ModelName().fit(x_train, y_train)\n",
        "  y_pred=model.predict(x_test)\n",
        "  accuracy=accuracy_score(y_test, y_pred)\n",
        "  mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "  aberr=metrics.mean_absolute_error(y_test, y_pred)\n",
        "  y_pred=model.predict(test_data)\n",
        "  res=\"Accuracy: \" + str(accuracy) + \" MSE: \" + str(mse) + \" MAE: \" + str(aberr) + \"   \" +str(y_pred[0])\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifFgHWjDoHle"
      },
      "outputs": [],
      "source": [
        "# Checking for different models\n",
        "test_data=np.array([[102.4824,25.0,0,41.0,0.96,1220,164141591,591]])\n",
        "print(classification_model_selection(RandomForestClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(AdaBoostClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(GradientBoostingClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(ExtraTreesClassifier, x_train, y_train, x_test, y_test,test_data))\n",
        "print(classification_model_selection(DecisionTreeClassifier, x_train, y_train, x_test, y_test,test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u47zdBb3hZX"
      },
      "outputs": [],
      "source": [
        "  # This method is used to predict the status based on its processing time and accuracy\n",
        "  model = RandomForestClassifier().fit(x_train, y_train)\n",
        "  y_pred=model.predict(x_test)\n",
        "  test_data=np.array([[102.4824,25.0,0,41.0,0.96,1220,164141591,591]])\n",
        "  y_pred=model.predict(test_data)\n",
        "  y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiCzVNTFouK7"
      },
      "outputs": [],
      "source": [
        "df_clssfctn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "JV2oIl29WWFI"
      },
      "outputs": [],
      "source": [
        "# write picket for classification\n",
        "with open('/content/classification_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "pyx1DW6LWWJ5"
      },
      "outputs": [],
      "source": [
        "# load the pickle model to predict status\n",
        "\n",
        "with open('/content/classification_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQwI0cfVYNQ_"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(np.array([[406.6865,25.0,0,41.0,0.71,1240,164141591,607]]))\n",
        "y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "VcyNEKhaWWdu"
      },
      "outputs": [],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFaW88e3MbIb",
        "outputId": "328f5e15-4eb2-4503-9fcb-d869208fa893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "# Streamlit file for deployment\n",
        "%%writefile app.py\n",
        "import numpy as np\n",
        "import pickle\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "#streamlit  page setting\n",
        "icon = Image.open(\"ml.jpg\")\n",
        "st.set_page_config(page_title= \"Copper EDA - Kavitha\",\n",
        "                page_icon= icon,\n",
        "                layout= \"wide\",\n",
        "                initial_sidebar_state= \"expanded\",\n",
        "                )\n",
        "\n",
        "st.subheader(\":blue[Industrial Copper Modeling]\")\n",
        "tab1,tab2,tab3=st.tabs([\":blue[Selling Price Prediction]\",\":blue[Status Prediction]\",\":blue[About]\"])\n",
        "\n",
        "with tab1:\n",
        "  col1,col2,col3=st.columns(3)\n",
        "  with col1:\n",
        "    txt_width=st.number_input(\"Enter the width\")\n",
        "    #res=checkempty(txt_width,\"width\")\n",
        "  with col2:\n",
        "    txt_quantity_tons=st.number_input(\"Enter the quantity in tons\")\n",
        "  with col3:\n",
        "    txt_thickness=st.number_input(\"Enter the thickness\")\n",
        "  if st.button(\"Predict Selling Price\", key=\"predict\"):\n",
        "      # load the regression pickle model\n",
        "      with open('/content/regression_model.pkl', 'rb') as f:\n",
        "          model = pickle.load(f)\n",
        "\n",
        "      # make array for all user input values in required order for model prediction\n",
        "      user_data = np.array([[txt_width,\n",
        "                          np.log(float(txt_quantity_tons)),\n",
        "                          np.log(float(txt_thickness))]])\n",
        "\n",
        "      # model predict the selling price based on user input\n",
        "      y_pred = model.predict(user_data)\n",
        "\n",
        "      # inverse transformation for log transformation data\n",
        "      selling_price = np.exp(y_pred[0])\n",
        "\n",
        "      # round the value with 2 decimal point\n",
        "      selling_price = round(selling_price, 2)\n",
        "      st.write(\"Predicted Selling Price: \", selling_price)\n",
        "\n",
        "with tab2:\n",
        "  col4,col5,col6=st.columns(3)\n",
        "  with col4:\n",
        "    txt_quantity_tons=st.number_input(\"Enter the quantity tons\")\n",
        "    txt_country=st.number_input(\"Enter country\")\n",
        "    txt_item_type=st.number_input(\"Enter item type\")\n",
        "  with col5:\n",
        "    txt_application=st.number_input(\"Enter application\")\n",
        "    txt_thickness=st.number_input(\"Enter thickness\")\n",
        "    txt_width=st.number_input(\"Enter width\")\n",
        "  with col6:\n",
        "    txt_product_ref=st.number_input(\"Enter product ref\")\n",
        "    txt_selling_price=st.number_input(\"Enter selling price\")\n",
        "\n",
        "  if st.button(\"Predict Status\", key=\"Predict Status\"):\n",
        "      # load the classification pickle model\n",
        "      with open('/content/classification_model.pkl', 'rb') as f:\n",
        "          model = pickle.load(f)\n",
        "\n",
        "      user_data = np.array([[txt_quantity_tons, txt_country, txt_item_type, txt_application,\n",
        "                            txt_thickness, txt_width, txt_product_ref, txt_selling_price]])\n",
        "\n",
        "      # model predict status based on user input\n",
        "      y_pred = model.predict(user_data)\n",
        "\n",
        "      status = y_pred[0]\n",
        "      if status==0:\n",
        "        st.Success(\"Status: Lost - Failure\")\n",
        "      elif status==1:\n",
        "        st.Success(\"Won - Success\")\n",
        "with tab3:\n",
        "    st.caption(\":blue[Overview:]\")\n",
        "    st.caption(\":blue[Original Copper dataset has null and zero values]\")\n",
        "    st.caption(\":blue[Data Cleaning has done for the all the null values and negative values]\")\n",
        "    st.caption(\":blue[log transformation is applied for selling price prediction]\")\n",
        "    st.caption(\":blue[3 features(quantity tons, width and thickness) has been taken for selling price prediction]\")\n",
        "    st.caption(\":blue[Won and lost status has been taken for prediction other status data has been removed]\")\n",
        "    st.caption(\":blue[all features has been taken for status prediction except item date and delivery date]\")"
      ]
    }
}
